{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be50ed5",
   "metadata": {},
   "source": [
    "# 1. Credit card applications\n",
    "Comercial banks receive alot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example, manually analyzing these applications is mundane, error-prone, and time-consuming.\n",
    "\n",
    "In this notebook, an automated credit card approval predictor will be built by using machine learning techniques, just like real banks do. The Credit Card Approval dataset from the UCI Machine Learning Repository. (archive.ics.uci.edu/ml/datasets/credit+approval).\n",
    "\n",
    "The notebook is as follows:\n",
    "1-First, we load the dataset and have a check it out.\n",
    "2-It is possible to see that the dataset has a mixture of both numerical and non-numerical features, that it contains values from different ranges, plus it contains a number of missing entries.\n",
    "3-Preprocess will be performed to ensure that the machine learning model makes good predictions\n",
    "4-After the data is in a good shape, exploratory analysis will be done as well.\n",
    "5-Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a564a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
      "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
      "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
      "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
      "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
      "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n"
     ]
    }
   ],
   "source": [
    "#Pandas library is needed\n",
    "import pandas as pd\n",
    "\n",
    "#the dataset is loaded\n",
    "cc_apps = pd.read_csv(r'C:\\Users\\MacBook\\Desktop\\Python Jupyter notebook\\crx.data',header=None)\n",
    "\n",
    "print(cc_apps.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d437cd",
   "metadata": {},
   "source": [
    "# 2. Inspecting the applications\n",
    "\n",
    "The data seems a bit confusing at the first sight, but according to a blog, the features are as follows:\n",
    "Gender,Age,Debt,Married,BankCustomer,EducationLevel, Ethnicity, YearsEmployed, PriorDefault,Employed, CreditScore,DriversLicense, Citizen,ZipCode,Income and finally ApprovalStatus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1097a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "\n",
      "\n",
      "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
      "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
      "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
      "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
      "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
      "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
      "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
      "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
      "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
      "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
      "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
      "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
      "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
      "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
      "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
      "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
      "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
      "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n"
     ]
    }
   ],
   "source": [
    "#Print summary statistics\n",
    "print(cc_apps.describe())\n",
    "\n",
    "print('\\n') #Blank space\n",
    "\n",
    "#Print DataFrame information\n",
    "print(cc_apps.info())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#Inspect missing values in the dataset\n",
    "print(cc_apps.tail(17))\n",
    "\n",
    "#It is possible to see that the data set has a mixture of numerical and non-numerical features. \n",
    "#This can be fixed with preprocessing methods, but first we need to see if there are other issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29526b6a",
   "metadata": {},
   "source": [
    "# 3. Splitting the dataset into training and testing sets\n",
    "\n",
    "Ideally, no information from the test data should be used to preprocess the training data or should be used to direct the training process of a machine learning model. Hence, we first split the date and then preprocess it.\n",
    "\n",
    "Additionally, features like DriversLicense and Zipcode are not as important as other features. Therefore, they should be dropped to design the machine learning model with the best set of features. (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deab2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping features DriversLicense and ZipCode -->[11,13]\n",
    "cc_apps = cc_apps.drop([11,13],axis=1)\n",
    "\n",
    "#Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split into train and test sets\n",
    "cc_apps_train,cc_apps_test = train_test_split(cc_apps,test_size=33,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28db20",
   "metadata": {},
   "source": [
    "# 4. Handling the missing values (part 1)\n",
    "The dataset has missing values, which are labeled with '?'. These will be replaced with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6040f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy\n",
    "import numpy as np\n",
    "\n",
    "#Replace the '?'s with NaN in the train ant test sets\n",
    "cc_apps_train = cc_apps_train.replace(to_replace='?',value = np.NaN)\n",
    "cc_apps_test = cc_apps_test.replace(to_replace='?',value = np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ed97c",
   "metadata": {},
   "source": [
    "# 5.Handling the missing values (part 2)\n",
    "Why are missing values so important?Ignoring missing values can affect the performance of a machine learning model heavily. While ignoring the missing values our machine learning model may miss out on information about the dataset that may be useful for its training.\n",
    "\n",
    "To avoid this, we are going to impute the missing values with a strategy called mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766f3c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     11\n",
      "1     10\n",
      "2      0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "12     0\n",
      "14     0\n",
      "15     0\n",
      "dtype: int64\n",
      "0     1\n",
      "1     2\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MacBook\\AppData\\Local\\Temp\\ipykernel_8228\\1279698539.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  cc_apps_train.fillna(cc_apps_train.mean(), inplace = True)\n",
      "C:\\Users\\MacBook\\AppData\\Local\\Temp\\ipykernel_8228\\1279698539.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  cc_apps_test.fillna(cc_apps_test.mean(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "cc_apps_train.fillna(cc_apps_train.mean(), inplace = True)\n",
    "cc_apps_test.fillna(cc_apps_test.mean(), inplace = True)\n",
    "\n",
    "print(cc_apps_train.isna().sum())\n",
    "print(cc_apps_test.isna().sum())\n",
    "\n",
    "#As it can be seen, there are still some missing values in columns 0,1,3,4,5 and 6. All these columns contain non-numeric data\n",
    "#and this is why mean imputation strategy will not work here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48328e64",
   "metadata": {},
   "source": [
    "# 6. Handling the missing values (part 3)\n",
    "We are going to impute this non-numerical values with the most frequent values as present in the respective columns. This is a good practice when it comes to imputing missing values for categorical data in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c59e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Iterate over each column of cc_apps_train\n",
    "for col in cc_apps_train.columns:\n",
    "    if cc_apps_train[col].dtypes == 'object':\n",
    "        cc_apps_train = cc_apps_train.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        cc_apps_test = cc_apps_test.fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        \n",
    "print(cc_apps_train.isna().sum())\n",
    "print(cc_apps_test.isna().sum())      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f83cf",
   "metadata": {},
   "source": [
    "# 7. Preprocessing the data (part 1)\n",
    "Now that the missing values were handled, we will proceed to the preprocessing stage.\n",
    "\n",
    "First, we will be converting all the non-numeric values into numeric ones. We do this because not only it results in a faster computation but also many machine learning models (like XGBoost) (and especially the ones developed using scikit-learn) require the data to be in a strictly numeric format. We will do this by using the get_dummies() method from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9ecf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical features in the train and test sets independently\n",
    "cc_apps_train = pd.get_dummies(cc_apps_train)\n",
    "cc_apps_test = pd.get_dummies(cc_apps_test)\n",
    "\n",
    "# Reindex the columns of the test set aligning with the train set\n",
    "cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567a082",
   "metadata": {},
   "source": [
    "# 8.Preprocessing the data (part 2)\n",
    "Now, we are only left with one final preprocessing step of scaling before we can fit a machine learning model to the data.\n",
    "\n",
    "Now, let's try to understand what these scaled values mean in the real world. Let's use CreditScore as an example. The credit score of a person is their creditworthiness based on their credit history. The higher this number, the more financially trustworthy a person is considered to be. So, a CreditScore of 1 is the highest since we're rescaling all the values to the range of 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51137008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = cc_apps_train.iloc[:,:-1].values, cc_apps_train.iloc[:,[-1]].values\n",
    "X_test, y_test = cc_apps_test.iloc[:,:-1].values, cc_apps_test.iloc[:,[-1]].values\n",
    "\n",
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "rescaledX_train = scaler.fit_transform(X_train, y_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8924d",
   "metadata": {},
   "source": [
    "# 9. Fitting a logistic regression model to the train set\n",
    "Predicting if a credit card application will be approved or not is a classification task.\n",
    "\n",
    "Although we can measure correlation, that is outside the scope of this notebook, so we'll rely on our intuition that they indeed are correlated for now. Because of this correlation, we'll take advantage of the fact that generalized linear models perform well in these cases. Let's start our machine learning modeling with a Logistic Regression model (a generalized linear model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2fe8957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "# ... YOUR CODE FOR TASK 9 ...\n",
    "logreg.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f705b",
   "metadata": {},
   "source": [
    "# 10. Making predictions and evaluating performance\n",
    "But how well does our model perform?\n",
    "\n",
    "We will now evaluate our model on the test set with respect to classification accuracy. But we will also take a look the model's confusion matrix. In the case of predicting credit card applications, it is important to see if our machine learning model is equally capable of predicting approved and denied status, in line with the frequency of these labels in our original dataset. If our model is not performing well in this aspect, then it might end up approving the application that should have been approved. The confusion matrix helps us to view our model's performance from these aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  1.0\n",
      "\n",
      "\n",
      "[[13  0]\n",
      " [ 0 20]]\n"
     ]
    }
   ],
   "source": [
    "#Use our model to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "#Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Getting the accuracy score of the model\n",
    "print('Accuracy of logistic regression classifier: ',logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "print('\\n')\n",
    "#Printing the confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b15092",
   "metadata": {},
   "source": [
    "# 11. Grid searching and making the model perform better\n",
    "Our model was pretty good! In fact it was able to yield an accuracy score of 100%.\n",
    "\n",
    "For the confusion matrix, the first element of the of the first row of the confusion matrix denotes the true negatives meaning the number of negative instances (denied applications) predicted by the model correctly. And the last element of the second row of the confusion matrix denotes the true positives meaning the number of positive instances (approved applications) predicted by the model correctly.\n",
    "\n",
    "But if we hadn't got a perfect score what's to be done?. We can perform a grid search of the model parameters to improve the model's ability to predict credit card approvals.\n",
    "\n",
    "scikit-learn's implementation of logistic regression consists of different hyperparameters but we will grid search over the following two:\n",
    "\n",
    "tol\n",
    "max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb45c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\MacBook\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}\n",
      "Accuracy of logistic regression classifier:  LogisticRegression(tol=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define grid values for these two hyperparameters\n",
    "tol = [0.01,0.001,0.0001]\n",
    "max_iter = [100,150,200]\n",
    "param_grid = dict({'tol':tol,'max_iter':max_iter})\n",
    "\n",
    "#Initialize GridSearch with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg,param_grid = param_grid,cv=5)\n",
    "\n",
    "#Fit grid model\n",
    "grid_model_result = grid_model.fit(rescaledX_train,y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "print(\"Accuracy of logistic regression classifier: \", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2498bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
